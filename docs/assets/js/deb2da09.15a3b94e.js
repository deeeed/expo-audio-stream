"use strict";(self.webpackChunkdocumentation_site=self.webpackChunkdocumentation_site||[]).push([[504],{2220:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>d,contentTitle:()=>a,default:()=>u,frontMatter:()=>t,metadata:()=>s,toc:()=>c});var r=i(4848),o=i(8453);const t={id:"recording-config",title:"Recording Configuration",sidebar_label:"Recording Configuration"},a=void 0,s={id:"api-reference/recording-config",title:"Recording Configuration",description:"The recording configuration specifies the settings used for audio recording on different platforms. Below are the default settings for Android, iOS, and web platforms:",source:"@site/docs/api-reference/recording-config.md",sourceDirName:"api-reference",slug:"/api-reference/recording-config",permalink:"/expo-audio-stream/docs/api-reference/recording-config",draft:!1,unlisted:!1,tags:[],version:"current",frontMatter:{id:"recording-config",title:"Recording Configuration",sidebar_label:"Recording Configuration"},sidebar:"tutorialSidebar",previous:{title:"API Intro",permalink:"/expo-audio-stream/docs/api-reference/api-intro"},next:{title:"AudioRecording",permalink:"/expo-audio-stream/docs/api-reference/audio-recording"}},d={},c=[{value:"Platform-Specific Architecture",id:"platform-specific-architecture",level:2},{value:"Web",id:"web",level:3},{value:"Android",id:"android",level:3},{value:"iOS",id:"ios",level:3},{value:"Platform Differences",id:"platform-differences",level:2},{value:"Android and iOS",id:"android-and-ios",level:3},{value:"Web",id:"web-1",level:3},{value:"Current Challenges",id:"current-challenges",level:2},{value:"Recording Process",id:"recording-process",level:2},{value:"Example Usage",id:"example-usage",level:2}];function l(e){const n={code:"code",h2:"h2",h3:"h3",li:"li",p:"p",pre:"pre",ul:"ul",...(0,o.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.p,{children:"The recording configuration specifies the settings used for audio recording on different platforms. Below are the default settings for Android, iOS, and web platforms:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"On Android: 16kHz sample rate, 16-bit depth, 1 channel."}),"\n",(0,r.jsx)(n.li,{children:"On IOS: 48kHz sample rate, 16-bit depth, 1 channel."}),"\n",(0,r.jsx)(n.li,{children:"On the web, default configuration is 44.1kHz sample rate, 32-bit depth, 1 channel."}),"\n"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-tsx",children:'export interface RecordingConfig {\n    sampleRate?: SampleRate // Sample rate for recording\n    channels?: 1 | 2 // 1 or 2 (MONO or STEREO)\n    encoding?: EncodingType // Encoding type for the recording\n    interval?: number // Interval in milliseconds at which to emit recording data\n\n    // Optional parameters for audio processing\n    enableProcessing?: boolean // Boolean to enable/disable audio processing (default is false)\n    pointsPerSecond?: number // Number of data points to extract per second of audio (default is 1000)\n    algorithm?: string // Algorithm to use for amplitude computation (default is "rms")\n    features?: AudioFeaturesOptions // Feature options to extract (default is empty)\n\n    onAudioStream?: (_: AudioDataEvent) => Promise<void> // Callback function to handle audio stream\n    onAudioAnalysis?: (_: AudioAnalysisEventPayload) => Promise<void> // Callback function to handle audio features extraction results\n}\n\n'})}),"\n",(0,r.jsx)(n.h2,{id:"platform-specific-architecture",children:"Platform-Specific Architecture"}),"\n",(0,r.jsx)(n.h3,{id:"web",children:"Web"}),"\n",(0,r.jsxs)(n.p,{children:["On the web, the recording utilizes the ",(0,r.jsx)(n.code,{children:"AudioWorkletProcessor"})," for handling audio data. The ",(0,r.jsx)(n.code,{children:"AudioWorkletProcessor"})," allows for real-time audio processing directly in the browser, making it a powerful tool for web-based audio applications."]}),"\n",(0,r.jsx)(n.h3,{id:"android",children:"Android"}),"\n",(0,r.jsxs)(n.p,{children:["On Android, the recording is managed using Android's native ",(0,r.jsx)(n.code,{children:"AudioRecord"})," API along with ",(0,r.jsx)(n.code,{children:"AudioFormat"})," and ",(0,r.jsx)(n.code,{children:"MediaRecorder"}),". These classes are part of the Android framework and provide low-level access to audio hardware, allowing for high-quality audio recording."]}),"\n",(0,r.jsx)(n.h3,{id:"ios",children:"iOS"}),"\n",(0,r.jsxs)(n.p,{children:["On iOS, the recording is managed using ",(0,r.jsx)(n.code,{children:"AVAudioEngine"})," and related classes from the ",(0,r.jsx)(n.code,{children:"AVFoundation"})," framework. ",(0,r.jsx)(n.code,{children:"AVAudioEngine"})," provides a robust and flexible way to capture, process, and play audio, making it ideal for real-time audio applications on iOS devices."]}),"\n",(0,r.jsx)(n.h2,{id:"platform-differences",children:"Platform Differences"}),"\n",(0,r.jsx)(n.h3,{id:"android-and-ios",children:"Android and iOS"}),"\n",(0,r.jsx)(n.p,{children:"On Android and iOS, the library attempts to record audio in the specified format. However, due to platform limitations, it doesn't always natively allow obtaining the PCM output in the desired format. When this occurs, the recorded audio needs to be manually resampled to match the required configuration."}),"\n",(0,r.jsx)(n.h3,{id:"web-1",children:"Web"}),"\n",(0,r.jsx)(n.p,{children:"On the web, the default configuration is typically higher, with a 44.1kHz sample rate and 32-bit depth. This ensures better sound quality, but it can lead to issues when resampling is required to lower settings."}),"\n",(0,r.jsx)(n.h2,{id:"current-challenges",children:"Current Challenges"}),"\n",(0,r.jsx)(n.p,{children:"Currently, resampling audio to different sample rates and bit depths is not producing the desired quality results. This is an ongoing area of investigation to ensure that resampling defaults to lower settings without breaking the sound quality."}),"\n",(0,r.jsx)(n.h2,{id:"recording-process",children:"Recording Process"}),"\n",(0,r.jsxs)(n.p,{children:["To start recording, you use the ",(0,r.jsx)(n.code,{children:"startRecording"})," function which accepts a ",(0,r.jsx)(n.code,{children:"RecordingConfig"})," object. The output of this function is a ",(0,r.jsx)(n.code,{children:"StartRecordingResult"}),"."]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-tsx",children:"export interface StartRecordingResult {\n    fileUri: string\n    mimeType: string\n    channels?: number\n    bitDepth?: BitDepth\n    sampleRate?: SampleRate\n}\n"})}),"\n",(0,r.jsxs)(n.p,{children:["The ",(0,r.jsx)(n.code,{children:"StartRecordingResult"})," provides the actual values used for recording, which can be useful if some properties of ",(0,r.jsx)(n.code,{children:"RecordingConfig"})," are not accepted natively by the platform (e.g., the web only accepts 32-bit PCM)."]}),"\n",(0,r.jsx)(n.h2,{id:"example-usage",children:"Example Usage"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-tsx",children:"import { useAudioRecorder } from '@siteed/expo-audio-stream';\n\nconst config = {\n    sampleRate: 16000,\n    channels: 1,\n    encoding: 'pcm_16bit',\n    interval: 500,\n    enableProcessing: true,\n    pointsPerSecond: 1000,\n    algorithm: 'rms',\n    features: { energy: true, rms: true },\n    onAudioStream: async (event) => {\n        console.log('Audio data:', event);\n    },\n    onAudioAnalysis: async (data) => {\n        console.log('Processing:', data);\n    },\n};\n\nconst {\n    startRecording,\n    stopRecording,\n    isRecording,\n    durationMs,\n    size,\n} = useAudioRecorder({ debug: true });\n\nconst handleStart = async () => {\n    const { granted } = await Audio.requestPermissionsAsync();\n    if (granted) {\n        const result = await startRecording(config);\n        console.log('Recording started with config:', result);\n    }\n};\n\nconst handleStop = async () => {\n    const result = await stopRecording();\n    console.log('Recording stopped with result:', result);\n};\n"})})]})}function u(e={}){const{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(l,{...e})}):l(e)}},8453:(e,n,i)=>{i.d(n,{R:()=>a,x:()=>s});var r=i(6540);const o={},t=r.createContext(o);function a(e){const n=r.useContext(t);return r.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function s(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:a(e.components),r.createElement(t.Provider,{value:n},e.children)}}}]);