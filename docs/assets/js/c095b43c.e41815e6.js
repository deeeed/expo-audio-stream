"use strict";(self.webpackChunkdocumentation_site=self.webpackChunkdocumentation_site||[]).push([[36],{1876:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>s,contentTitle:()=>d,default:()=>l,frontMatter:()=>r,metadata:()=>o,toc:()=>c});var a=t(4848),i=t(8453);const r={id:"audio-data-event",title:"AudioDataEvent",sidebar_label:"AudioDataEvent"},d="AudioDataEvent",o={id:"api-reference/audio-data-event",title:"AudioDataEvent",description:"The AudioDataEvent interface represents the audio data being streamed at the specified interval. The size of the buffer will depend on the sampleRate and encoding configuration. This buffer can be used for further processing.",source:"@site/docs/api-reference/audio-data-event.md",sourceDirName:"api-reference",slug:"/api-reference/audio-data-event",permalink:"/expo-audio-stream/docs/api-reference/audio-data-event",draft:!1,unlisted:!1,tags:[],version:"current",frontMatter:{id:"audio-data-event",title:"AudioDataEvent",sidebar_label:"AudioDataEvent"},sidebar:"tutorialSidebar",previous:{title:"AudioRecording",permalink:"/expo-audio-stream/docs/api-reference/audio-recording"},next:{title:"Audio Features",permalink:"/expo-audio-stream/docs/api-reference/audio-features/audio-analysis"}},s={},c=[{value:"Interface",id:"interface",level:2},{value:"Data Field",id:"data-field",level:2},{value:"Example Usage",id:"example-usage",level:2}];function u(e){const n={code:"code",h1:"h1",h2:"h2",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,i.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(n.h1,{id:"audiodataevent",children:"AudioDataEvent"}),"\n",(0,a.jsxs)(n.p,{children:["The ",(0,a.jsx)(n.code,{children:"AudioDataEvent"})," interface represents the audio data being streamed at the specified interval. The size of the buffer will depend on the ",(0,a.jsx)(n.code,{children:"sampleRate"})," and ",(0,a.jsx)(n.code,{children:"encoding"})," configuration. This buffer can be used for further processing."]}),"\n",(0,a.jsx)(n.h2,{id:"interface",children:"Interface"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-ts",children:"export interface AudioDataEvent {\n    data: string | ArrayBuffer // The audio data in the specified format\n    position: number // The position in the stream\n    fileUri: string // The URI of the audio file\n    eventDataSize: number // The size of the event data\n    totalSize: number // The total size of the recorded data\n}\n"})}),"\n",(0,a.jsx)(n.h2,{id:"data-field",children:"Data Field"}),"\n",(0,a.jsxs)(n.p,{children:["The ",(0,a.jsx)(n.code,{children:"data"})," field can be either a ",(0,a.jsx)(n.code,{children:"string"})," or an ",(0,a.jsx)(n.code,{children:"ArrayBuffer"}),":"]}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Native (Android/iOS)"}),": The ",(0,a.jsx)(n.code,{children:"data"})," is a ",(0,a.jsx)(n.code,{children:"string"})," representing the base64-encoded version of the audio binary. We use base64 encoding because we cannot directly access the raw audio data from Android or iOS."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Web"}),": The ",(0,a.jsx)(n.code,{children:"data"})," is an ",(0,a.jsx)(n.code,{children:"ArrayBuffer"})," containing the raw audio data."]}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"example-usage",children:"Example Usage"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-tsx",children:"import { useAudioRecorder } from '@siteed/expo-audio-stream';\n\nconst config = {\n    onAudioStream: async (event: AudioDataEvent) => {\n        console.log('Audio data:', event);\n        // Process the audio data here\n    },\n};\n\nconst {\n    startRecording,\n} = useAudioRecorder({ debug: true });\n\nconst handleStart = async () => {\n    const { granted } = await Audio.requestPermissionsAsync();\n    if (granted) {\n        await startRecording(config);\n    }\n};\n\n"})})]})}function l(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(u,{...e})}):u(e)}},8453:(e,n,t)=>{t.d(n,{R:()=>d,x:()=>o});var a=t(6540);const i={},r=a.createContext(i);function d(e){const n=a.useContext(r);return a.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:d(e.components),a.createElement(r.Provider,{value:n},e.children)}}}]);