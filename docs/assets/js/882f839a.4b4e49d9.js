"use strict";(self.webpackChunkdocumentation_site=self.webpackChunkdocumentation_site||[]).push([[7698],{2519:(e,r,n)=>{n.r(r),n.d(r,{assets:()=>c,contentTitle:()=>l,default:()=>h,frontMatter:()=>a,metadata:()=>t,toc:()=>o});const t=JSON.parse('{"id":"api-reference/audio-processing/extract-mel-spectrogram","title":"extractMelSpectrogram","description":"The extractMelSpectrogram function generates a mel spectrogram from an audio file. Mel spectrograms are frequency-domain representations of audio that are particularly useful for machine learning applications and audio visualization.","source":"@site/docs/api-reference/audio-processing/extract-mel-spectrogram.md","sourceDirName":"api-reference/audio-processing","slug":"/api-reference/audio-processing/extract-mel-spectrogram","permalink":"/expo-audio-stream/docs/api-reference/audio-processing/extract-mel-spectrogram","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{"id":"extract-mel-spectrogram","title":"extractMelSpectrogram","sidebar_label":"extractMelSpectrogram"},"sidebar":"tutorialSidebar","previous":{"title":"Usage Example","permalink":"/expo-audio-stream/docs/api-reference/audio-features/audio-analysis-example"},"next":{"title":"trimAudio","permalink":"/expo-audio-stream/docs/api-reference/audio-processing/trim-audio"}}');var i=n(4848),s=n(8453);const a={id:"extract-mel-spectrogram",title:"extractMelSpectrogram",sidebar_label:"extractMelSpectrogram"},l="extractMelSpectrogram",c={},o=[{value:"Syntax",id:"syntax",level:2},{value:"Parameters",id:"parameters",level:2},{value:"Return Value",id:"return-value",level:2},{value:"Example",id:"example",level:2},{value:"Visualization Example",id:"visualization-example",level:2},{value:"Performance Considerations",id:"performance-considerations",level:2}];function d(e){const r={code:"code",h1:"h1",h2:"h2",header:"header",li:"li",p:"p",pre:"pre",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,s.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(r.header,{children:(0,i.jsx)(r.h1,{id:"extractmelspectrogram",children:"extractMelSpectrogram"})}),"\n",(0,i.jsxs)(r.p,{children:["The ",(0,i.jsx)(r.code,{children:"extractMelSpectrogram"})," function generates a mel spectrogram from an audio file. Mel spectrograms are frequency-domain representations of audio that are particularly useful for machine learning applications and audio visualization."]}),"\n",(0,i.jsx)(r.h2,{id:"syntax",children:"Syntax"}),"\n",(0,i.jsx)(r.pre,{children:(0,i.jsx)(r.code,{className:"language-typescript",children:"async function extractMelSpectrogram(options: MelSpectrogramOptions): Promise<MelSpectrogramResult>\n"})}),"\n",(0,i.jsx)(r.h2,{id:"parameters",children:"Parameters"}),"\n",(0,i.jsx)(r.p,{children:"The function accepts a single object with the following properties:"}),"\n",(0,i.jsxs)(r.table,{children:[(0,i.jsx)(r.thead,{children:(0,i.jsxs)(r.tr,{children:[(0,i.jsx)(r.th,{children:"Property"}),(0,i.jsx)(r.th,{children:"Type"}),(0,i.jsx)(r.th,{children:"Required"}),(0,i.jsx)(r.th,{children:"Default"}),(0,i.jsx)(r.th,{children:"Description"})]})}),(0,i.jsxs)(r.tbody,{children:[(0,i.jsxs)(r.tr,{children:[(0,i.jsx)(r.td,{children:(0,i.jsx)(r.code,{children:"fileUri"})}),(0,i.jsx)(r.td,{children:"string"}),(0,i.jsx)(r.td,{children:"Yes"}),(0,i.jsx)(r.td,{children:"-"}),(0,i.jsx)(r.td,{children:"Path to the audio file to analyze"})]}),(0,i.jsxs)(r.tr,{children:[(0,i.jsx)(r.td,{children:(0,i.jsx)(r.code,{children:"windowSizeMs"})}),(0,i.jsx)(r.td,{children:"number"}),(0,i.jsx)(r.td,{children:"No"}),(0,i.jsx)(r.td,{children:"25"}),(0,i.jsx)(r.td,{children:"Window size in milliseconds for the STFT"})]}),(0,i.jsxs)(r.tr,{children:[(0,i.jsx)(r.td,{children:(0,i.jsx)(r.code,{children:"hopLengthMs"})}),(0,i.jsx)(r.td,{children:"number"}),(0,i.jsx)(r.td,{children:"No"}),(0,i.jsx)(r.td,{children:"10"}),(0,i.jsx)(r.td,{children:"Hop length in milliseconds between consecutive frames"})]}),(0,i.jsxs)(r.tr,{children:[(0,i.jsx)(r.td,{children:(0,i.jsx)(r.code,{children:"nMels"})}),(0,i.jsx)(r.td,{children:"number"}),(0,i.jsx)(r.td,{children:"No"}),(0,i.jsx)(r.td,{children:"40"}),(0,i.jsx)(r.td,{children:"Number of mel bands to generate"})]}),(0,i.jsxs)(r.tr,{children:[(0,i.jsx)(r.td,{children:(0,i.jsx)(r.code,{children:"fMin"})}),(0,i.jsx)(r.td,{children:"number"}),(0,i.jsx)(r.td,{children:"No"}),(0,i.jsx)(r.td,{children:"0"}),(0,i.jsx)(r.td,{children:"Lowest frequency (in Hz)"})]}),(0,i.jsxs)(r.tr,{children:[(0,i.jsx)(r.td,{children:(0,i.jsx)(r.code,{children:"fMax"})}),(0,i.jsx)(r.td,{children:"number"}),(0,i.jsx)(r.td,{children:"No"}),(0,i.jsx)(r.td,{children:"22050"}),(0,i.jsx)(r.td,{children:"Highest frequency (in Hz). If null, use sampleRate/2"})]}),(0,i.jsxs)(r.tr,{children:[(0,i.jsx)(r.td,{children:(0,i.jsx)(r.code,{children:"normalize"})}),(0,i.jsx)(r.td,{children:"boolean"}),(0,i.jsx)(r.td,{children:"No"}),(0,i.jsx)(r.td,{children:"true"}),(0,i.jsx)(r.td,{children:"Whether to normalize the spectrogram"})]})]})]}),"\n",(0,i.jsx)(r.h2,{id:"return-value",children:"Return Value"}),"\n",(0,i.jsxs)(r.p,{children:["The function returns a Promise that resolves to a ",(0,i.jsx)(r.code,{children:"MelSpectrogramResult"})," object with the following properties:"]}),"\n",(0,i.jsxs)(r.table,{children:[(0,i.jsx)(r.thead,{children:(0,i.jsxs)(r.tr,{children:[(0,i.jsx)(r.th,{children:"Property"}),(0,i.jsx)(r.th,{children:"Type"}),(0,i.jsx)(r.th,{children:"Description"})]})}),(0,i.jsxs)(r.tbody,{children:[(0,i.jsxs)(r.tr,{children:[(0,i.jsx)(r.td,{children:(0,i.jsx)(r.code,{children:"melSpectrogram"})}),(0,i.jsx)(r.td,{children:"number[][]"}),(0,i.jsx)(r.td,{children:"2D array containing the mel spectrogram values"})]}),(0,i.jsxs)(r.tr,{children:[(0,i.jsx)(r.td,{children:(0,i.jsx)(r.code,{children:"timeAxis"})}),(0,i.jsx)(r.td,{children:"number[]"}),(0,i.jsx)(r.td,{children:"Time values for each frame (in seconds)"})]}),(0,i.jsxs)(r.tr,{children:[(0,i.jsx)(r.td,{children:(0,i.jsx)(r.code,{children:"freqAxis"})}),(0,i.jsx)(r.td,{children:"number[]"}),(0,i.jsx)(r.td,{children:"Frequency values for each mel band (in Hz)"})]}),(0,i.jsxs)(r.tr,{children:[(0,i.jsx)(r.td,{children:(0,i.jsx)(r.code,{children:"durationMs"})}),(0,i.jsx)(r.td,{children:"number"}),(0,i.jsx)(r.td,{children:"Duration of the audio in milliseconds"})]}),(0,i.jsxs)(r.tr,{children:[(0,i.jsx)(r.td,{children:(0,i.jsx)(r.code,{children:"sampleRate"})}),(0,i.jsx)(r.td,{children:"number"}),(0,i.jsx)(r.td,{children:"Sample rate of the audio in Hz"})]}),(0,i.jsxs)(r.tr,{children:[(0,i.jsx)(r.td,{children:(0,i.jsx)(r.code,{children:"windowSizeMs"})}),(0,i.jsx)(r.td,{children:"number"}),(0,i.jsx)(r.td,{children:"Window size used for the STFT in milliseconds"})]}),(0,i.jsxs)(r.tr,{children:[(0,i.jsx)(r.td,{children:(0,i.jsx)(r.code,{children:"hopLengthMs"})}),(0,i.jsx)(r.td,{children:"number"}),(0,i.jsx)(r.td,{children:"Hop length used between consecutive frames in milliseconds"})]}),(0,i.jsxs)(r.tr,{children:[(0,i.jsx)(r.td,{children:(0,i.jsx)(r.code,{children:"nMels"})}),(0,i.jsx)(r.td,{children:"number"}),(0,i.jsx)(r.td,{children:"Number of mel bands generated"})]})]})]}),"\n",(0,i.jsx)(r.h2,{id:"example",children:"Example"}),"\n",(0,i.jsx)(r.pre,{children:(0,i.jsx)(r.code,{className:"language-typescript",children:"import { extractMelSpectrogram } from '@siteed/expo-audio-studio';\n\nasync function generateMelSpectrogram() {\n  try {\n    const result = await extractMelSpectrogram({\n      fileUri: 'path/to/audio.wav',\n      windowSizeMs: 25,\n      hopLengthMs: 10,\n      nMels: 40,\n      fMin: 20,\n      fMax: 8000,\n      normalize: true\n    });\n    \n    console.log(`Generated mel spectrogram with ${result.melSpectrogram.length} frames`);\n    console.log(`Each frame has ${result.melSpectrogram[0].length} mel bands`);\n    console.log(`Time range: ${result.timeAxis[0]}s to ${result.timeAxis[result.timeAxis.length-1]}s`);\n    console.log(`Frequency range: ${result.freqAxis[0]}Hz to ${result.freqAxis[result.freqAxis.length-1]}Hz`);\n    \n    // Use the mel spectrogram data for visualization or machine learning\n    return result;\n  } catch (error) {\n    console.error('Error generating mel spectrogram:', error);\n    throw error;\n  }\n}\n"})}),"\n",(0,i.jsx)(r.h2,{id:"visualization-example",children:"Visualization Example"}),"\n",(0,i.jsxs)(r.p,{children:["Here's an example of how to visualize the mel spectrogram using the ",(0,i.jsx)(r.code,{children:"@siteed/expo-audio-ui"})," package:"]}),"\n",(0,i.jsx)(r.pre,{children:(0,i.jsx)(r.code,{className:"language-typescript",children:"import React from 'react';\nimport { View } from 'react-native';\nimport { MelSpectrogramVisualizer } from '@siteed/expo-audio-ui';\nimport { extractMelSpectrogram } from '@siteed/expo-audio-studio';\n\nconst SpectrogramView = ({ audioUri }) => {\n  const [spectrogramData, setSpectrogramData] = React.useState(null);\n  \n  React.useEffect(() => {\n    async function loadSpectrogram() {\n      if (audioUri) {\n        const data = await extractMelSpectrogram({\n          fileUri: audioUri,\n          nMels: 80,\n          windowSizeMs: 25,\n          hopLengthMs: 10\n        });\n        setSpectrogramData(data);\n      }\n    }\n    \n    loadSpectrogram();\n  }, [audioUri]);\n  \n  if (!spectrogramData) {\n    return <View style={{ height: 200 }} />;\n  }\n  \n  return (\n    <MelSpectrogramVisualizer\n      data={spectrogramData.melSpectrogram}\n      height={200}\n      width=\"100%\"\n      colorMap=\"viridis\"\n    />\n  );\n};\n\nexport default SpectrogramView;\n"})}),"\n",(0,i.jsx)(r.h2,{id:"performance-considerations",children:"Performance Considerations"}),"\n",(0,i.jsxs)(r.ul,{children:["\n",(0,i.jsx)(r.li,{children:"Generating mel spectrograms is computationally intensive, especially for longer audio files"}),"\n",(0,i.jsx)(r.li,{children:"Consider using a lower number of mel bands (e.g., 40 instead of 128) for better performance"}),"\n",(0,i.jsxs)(r.li,{children:["The ",(0,i.jsx)(r.code,{children:"windowSizeMs"})," and ",(0,i.jsx)(r.code,{children:"hopLengthMs"})," parameters affect both the resolution and the computation time"]}),"\n",(0,i.jsx)(r.li,{children:"For real-time applications, process shorter audio segments or use lower resolution parameters"}),"\n"]})]})}function h(e={}){const{wrapper:r}={...(0,s.R)(),...e.components};return r?(0,i.jsx)(r,{...e,children:(0,i.jsx)(d,{...e})}):d(e)}},8453:(e,r,n)=>{n.d(r,{R:()=>a,x:()=>l});var t=n(6540);const i={},s=t.createContext(i);function a(e){const r=t.useContext(s);return t.useMemo((function(){return"function"==typeof e?e(r):{...r,...e}}),[r,e])}function l(e){let r;return r=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:a(e.components),t.createElement(s.Provider,{value:r},e.children)}}}]);