"use strict";(self.webpackChunkdocumentation_site=self.webpackChunkdocumentation_site||[]).push([[9924],{8453:(e,n,r)=>{r.d(n,{R:()=>s,x:()=>d});var t=r(6540);const o={},i=t.createContext(o);function s(e){const n=t.useContext(i);return t.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function d(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:s(e.components),t.createElement(i.Provider,{value:n},e.children)}},9304:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>a,contentTitle:()=>d,default:()=>u,frontMatter:()=>s,metadata:()=>t,toc:()=>c});const t=JSON.parse('{"id":"usage/standalone-recording","title":"Standalone Recording","description":"This library provides hooks for recording audio. Here, we demonstrate how to use useAudioRecorder for standalone recording.","source":"@site/docs/usage/standalone-recording.md","sourceDirName":"usage","slug":"/usage/standalone-recording","permalink":"/expo-audio-stream/docs/usage/standalone-recording","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{"id":"standalone-recording","title":"Standalone Recording","sidebar_label":"Standalone Recording"},"sidebar":"tutorialSidebar","previous":{"title":"Installation","permalink":"/expo-audio-stream/docs/installation"},"next":{"title":"Shared Recording","permalink":"/expo-audio-stream/docs/usage/shared-recording"}}');var o=r(4848),i=r(8453);const s={id:"standalone-recording",title:"Standalone Recording",sidebar_label:"Standalone Recording"},d="Standalone Recording",a={},c=[{value:"Standalone Usage",id:"standalone-usage",level:2},{value:"Options",id:"options",level:4},{value:"Return Value",id:"return-value",level:4}];function l(e){const n={code:"code",h1:"h1",h2:"h2",h4:"h4",header:"header",p:"p",pre:"pre",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",...(0,i.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(n.header,{children:(0,o.jsx)(n.h1,{id:"standalone-recording",children:"Standalone Recording"})}),"\n",(0,o.jsxs)(n.p,{children:["This library provides hooks for recording audio. Here, we demonstrate how to use ",(0,o.jsx)(n.code,{children:"useAudioRecorder"})," for standalone recording."]}),"\n",(0,o.jsx)(n.h2,{id:"standalone-usage",children:"Standalone Usage"}),"\n",(0,o.jsxs)(n.p,{children:["The ",(0,o.jsx)(n.code,{children:"useAudioRecorder"})," hook provides a complete API for recording audio in a single component. It manages the recording state internally and provides methods for controlling the recording process."]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-tsx",children:"import {\n  AudioRecording,\n  useAudioRecorder,\n  ExpoAudioStreamModule,\n  RecordingConfig\n} from '@siteed/expo-audio-studio'\nimport { useAudioPlayer } from 'expo-audio'\nimport { useState } from 'react'\nimport { Button, StyleSheet, Text, View } from 'react-native'\n\nconst STOP_BUTTON_COLOR = 'red'\n\nconst styles = StyleSheet.create({\n  container: {\n      gap: 10,\n      margin: 40,\n      padding: 20,\n  },\n  stopButton: {\n      backgroundColor: 'red',\n  },\n})\n\nexport default function App() {\n  const {\n      startRecording,\n      stopRecording,\n      pauseRecording,\n      resumeRecording,\n      durationMs,\n      size,\n      isRecording,\n      isPaused,\n      analysisData, // Audio analysis data if enableProcessing is true\n      compression, // Compression information if compression is enabled\n  } = useAudioRecorder()\n  const [audioResult, setAudioResult] = useState<AudioRecording | null>(null)\n  const player = useAudioPlayer(audioResult?.fileUri ?? \"\")\n\n  const handleStart = async () => {\n    const { status } = await ExpoAudioStreamModule.requestPermissionsAsync()\n    if (status !== 'granted') {\n      return\n    }\n      \n    // Configure recording options\n    const config: RecordingConfig = {\n        interval: 500, // Emit recording data every 500ms\n        enableProcessing: true, // Enable audio analysis\n        sampleRate: 44100, // Sample rate in Hz (16000, 44100, or 48000)\n        channels: 1, // Mono recording\n        encoding: 'pcm_16bit', // PCM encoding (pcm_8bit, pcm_16bit, pcm_32bit)\n        \n        // Optional: Configure audio output files\n        output: {\n            // Primary WAV file (enabled by default)\n            primary: {\n                enabled: true, // Set to false to disable WAV file creation\n            },\n            // Compressed file (disabled by default)\n            compressed: {\n                enabled: false, // Set to true to enable compression\n                format: 'aac', // 'aac' or 'opus'\n                bitrate: 128000, // Bitrate in bits per second\n            }\n        },\n        \n        // Optional: Handle audio stream data\n        onAudioStream: async (audioData) => {\n            console.log(`onAudioStream`, audioData)\n        },\n        \n        // Optional: Handle audio analysis data\n        onAudioAnalysis: async (analysisEvent) => {\n            console.log(`onAudioAnalysis`, analysisEvent)\n        },\n        \n        // Optional: Handle recording interruptions\n        onRecordingInterrupted: (event) => {\n            console.log(`Recording interrupted: ${event.reason}`)\n        },\n        \n        // Optional: Auto-resume after interruption\n        autoResumeAfterInterruption: false,\n        \n        // Optional: Buffer duration control\n        bufferDurationSeconds: 0.1, // Buffer size in seconds\n        // Default: undefined (uses 1024 frames, but iOS enforces minimum 0.1s)\n    }\n    \n    const startResult = await startRecording(config)\n    return startResult\n  }\n\n  const handleStop = async () => {\n      const result = await stopRecording()\n      setAudioResult(result)\n  }\n\n  const handlePlay = async () => {\n      if (player) {\n          player.play()\n      }\n  }\n\n  const renderRecording = () => (\n      <View style={styles.container}>\n          <Text>Duration: {durationMs / 1000} seconds</Text>\n          <Text>Size: {size} bytes</Text>\n          <Button title=\"Pause Recording\" onPress={pauseRecording} />\n          <Button\n              title=\"Stop Recording\"\n              onPress={handleStop}\n              color={STOP_BUTTON_COLOR}\n          />\n      </View>\n  )\n\n  const renderPaused = () => (\n      <View style={styles.container}>\n          <Text>Duration: {durationMs / 1000} seconds</Text>\n          <Text>Size: {size} bytes</Text>\n          <Button title=\"Resume Recording\" onPress={resumeRecording} />\n          <Button\n              title=\"Stop Recording\"\n              color={STOP_BUTTON_COLOR}\n              onPress={handleStop}\n          />\n      </View>\n  )\n\n  const renderStopped = () => (\n      <View style={styles.container}>\n          <Button title=\"Start Recording\" onPress={handleStart} />\n          {audioResult && (\n              <View>\n                  <Button title=\"Play Recording\" onPress={handlePlay} />\n              </View>\n          )}\n      </View>\n  )\n\n  return (\n      <>\n          {isRecording\n              ? renderRecording()\n              : isPaused\n                ? renderPaused()\n                : renderStopped()}\n      </>\n  )\n}\n\n## API Reference\n\n### useAudioRecorder Hook\n\n```tsx\nconst recorder = useAudioRecorder(options?: UseAudioRecorderProps)\n"})}),"\n",(0,o.jsx)(n.h4,{id:"options",children:"Options"}),"\n",(0,o.jsxs)(n.table,{children:[(0,o.jsx)(n.thead,{children:(0,o.jsxs)(n.tr,{children:[(0,o.jsx)(n.th,{children:"Property"}),(0,o.jsx)(n.th,{children:"Type"}),(0,o.jsx)(n.th,{children:"Description"})]})}),(0,o.jsx)(n.tbody,{children:(0,o.jsxs)(n.tr,{children:[(0,o.jsx)(n.td,{children:(0,o.jsx)(n.code,{children:"logger"})}),(0,o.jsx)(n.td,{children:(0,o.jsx)(n.code,{children:"ConsoleLike"})}),(0,o.jsx)(n.td,{children:"Optional logger for debugging"})]})})]}),"\n",(0,o.jsx)(n.h4,{id:"return-value",children:"Return Value"}),"\n",(0,o.jsxs)(n.table,{children:[(0,o.jsx)(n.thead,{children:(0,o.jsxs)(n.tr,{children:[(0,o.jsx)(n.th,{children:"Property"}),(0,o.jsx)(n.th,{children:"Type"}),(0,o.jsx)(n.th,{children:"Description"})]})}),(0,o.jsxs)(n.tbody,{children:[(0,o.jsxs)(n.tr,{children:[(0,o.jsx)(n.td,{children:(0,o.jsx)(n.code,{children:"startRecording"})}),(0,o.jsx)(n.td,{children:(0,o.jsx)(n.code,{children:"(config: RecordingConfig) => Promise<StartRecordingResult>"})}),(0,o.jsx)(n.td,{children:"Starts recording with the specified configuration"})]}),(0,o.jsxs)(n.tr,{children:[(0,o.jsx)(n.td,{children:(0,o.jsx)(n.code,{children:"stopRecording"})}),(0,o.jsx)(n.td,{children:(0,o.jsx)(n.code,{children:"() => Promise<AudioRecording>"})}),(0,o.jsx)(n.td,{children:"Stops the current recording and returns the recording data"})]}),(0,o.jsxs)(n.tr,{children:[(0,o.jsx)(n.td,{children:(0,o.jsx)(n.code,{children:"pauseRecording"})}),(0,o.jsx)(n.td,{children:(0,o.jsx)(n.code,{children:"() => Promise<void>"})}),(0,o.jsx)(n.td,{children:"Pauses the current recording"})]}),(0,o.jsxs)(n.tr,{children:[(0,o.jsx)(n.td,{children:(0,o.jsx)(n.code,{children:"resumeRecording"})}),(0,o.jsx)(n.td,{children:(0,o.jsx)(n.code,{children:"() => Promise<void>"})}),(0,o.jsx)(n.td,{children:"Resumes a paused recording"})]}),(0,o.jsxs)(n.tr,{children:[(0,o.jsx)(n.td,{children:(0,o.jsx)(n.code,{children:"isRecording"})}),(0,o.jsx)(n.td,{children:(0,o.jsx)(n.code,{children:"boolean"})}),(0,o.jsx)(n.td,{children:"Indicates whether recording is currently active"})]}),(0,o.jsxs)(n.tr,{children:[(0,o.jsx)(n.td,{children:(0,o.jsx)(n.code,{children:"isPaused"})}),(0,o.jsx)(n.td,{children:(0,o.jsx)(n.code,{children:"boolean"})}),(0,o.jsx)(n.td,{children:"Indicates whether recording is in a paused state"})]}),(0,o.jsxs)(n.tr,{children:[(0,o.jsx)(n.td,{children:(0,o.jsx)(n.code,{children:"durationMs"})}),(0,o.jsx)(n.td,{children:(0,o.jsx)(n.code,{children:"number"})}),(0,o.jsx)(n.td,{children:"Duration of the current recording in milliseconds"})]}),(0,o.jsxs)(n.tr,{children:[(0,o.jsx)(n.td,{children:(0,o.jsx)(n.code,{children:"size"})}),(0,o.jsx)(n.td,{children:(0,o.jsx)(n.code,{children:"number"})}),(0,o.jsx)(n.td,{children:"Size of the recorded audio in bytes"})]}),(0,o.jsxs)(n.tr,{children:[(0,o.jsx)(n.td,{children:(0,o.jsx)(n.code,{children:"compression"})}),(0,o.jsx)(n.td,{children:(0,o.jsx)(n.code,{children:"CompressionInfo | undefined"})}),(0,o.jsx)(n.td,{children:"Information about compression if enabled"})]}),(0,o.jsxs)(n.tr,{children:[(0,o.jsx)(n.td,{children:(0,o.jsx)(n.code,{children:"analysisData"})}),(0,o.jsx)(n.td,{children:(0,o.jsx)(n.code,{children:"AudioAnalysis | undefined"})}),(0,o.jsx)(n.td,{children:"Analysis data for the recording if processing was enabled"})]})]})]})]})}function u(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(l,{...e})}):l(e)}}}]);