"use strict";(self.webpackChunkdocumentation_site=self.webpackChunkdocumentation_site||[]).push([[6794],{6073:(e,i,n)=>{n.r(i),n.d(i,{assets:()=>l,contentTitle:()=>o,default:()=>u,frontMatter:()=>t,metadata:()=>s,toc:()=>c});const s=JSON.parse('{"id":"api-reference/audio-features/audio-analysis-overview","title":"Audio Analysis Overview","description":"The @siteed/expo-audio-studio library provides powerful audio analysis capabilities that allow you to extract various features from audio recordings. These features can be used for visualization, audio fingerprinting, speech recognition preprocessing, and more.","source":"@site/docs/api-reference/audio-features/audio-analysis-overview.md","sourceDirName":"api-reference/audio-features","slug":"/api-reference/audio-features/audio-analysis-overview","permalink":"/expo-audio-stream/docs/api-reference/audio-features/audio-analysis-overview","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{"id":"audio-analysis-overview","title":"Audio Analysis Overview","sidebar_label":"Overview"},"sidebar":"tutorialSidebar","previous":{"title":"AudioDataEvent","permalink":"/expo-audio-stream/docs/api-reference/audio-data-event"},"next":{"title":"Audio Features","permalink":"/expo-audio-stream/docs/api-reference/audio-features/audio-analysis"}}');var r=n(4848),a=n(8453);const t={id:"audio-analysis-overview",title:"Audio Analysis Overview",sidebar_label:"Overview"},o="Audio Analysis Overview",l={},c=[{value:"Quick Start",id:"quick-start",level:2},{value:"Available Audio Features",id:"available-audio-features",level:2},{value:"Basic Analysis",id:"basic-analysis",level:3},{value:"Spectral Features",id:"spectral-features",level:3},{value:"Advanced Analysis",id:"advanced-analysis",level:3},{value:"Configuring Feature Extraction",id:"configuring-feature-extraction",level:2},{value:"Common Use Cases",id:"common-use-cases",level:2},{value:"Performance Considerations",id:"performance-considerations",level:2}];function d(e){const i={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,a.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(i.header,{children:(0,r.jsx)(i.h1,{id:"audio-analysis-overview",children:"Audio Analysis Overview"})}),"\n",(0,r.jsxs)(i.p,{children:["The ",(0,r.jsx)(i.code,{children:"@siteed/expo-audio-studio"})," library provides powerful audio analysis capabilities that allow you to extract various features from audio recordings. These features can be used for visualization, audio fingerprinting, speech recognition preprocessing, and more."]}),"\n",(0,r.jsx)(i.h2,{id:"quick-start",children:"Quick Start"}),"\n",(0,r.jsx)(i.pre,{children:(0,r.jsx)(i.code,{className:"language-typescript",children:"import { extractAudioAnalysis } from '@siteed/expo-audio-studio';\n\n// Extract audio analysis with specific features enabled\nconst analysis = await extractAudioAnalysis({\n  fileUri: 'path/to/recording.wav',\n  features: {\n    energy: true,     // Overall energy of the audio\n    rms: true,        // Root mean square (amplitude)\n    zcr: true,        // Zero-crossing rate\n    mfcc: true,       // Mel-frequency cepstral coefficients\n    spectralCentroid: true,  // Brightness of sound\n    tempo: true,      // Estimated BPM\n  }\n});\n\n// Access the analysis data\nconsole.log(`Audio duration: ${analysis.durationMs}ms`);\nconsole.log(`Sample rate: ${analysis.sampleRate}Hz`);\nconsole.log(`Number of data points: ${analysis.dataPoints.length}`);\n\n// Access features from a specific data point\nconst dataPoint = analysis.dataPoints[0];\nif (dataPoint.features) {\n  console.log(`RMS: ${dataPoint.features.rms}`);\n  console.log(`Energy: ${dataPoint.features.energy}`);\n  console.log(`Zero-crossing rate: ${dataPoint.features.zcr}`);\n}\n"})}),"\n",(0,r.jsx)(i.h2,{id:"available-audio-features",children:"Available Audio Features"}),"\n",(0,r.jsx)(i.p,{children:"The library supports extracting the following audio features:"}),"\n",(0,r.jsx)(i.h3,{id:"basic-analysis",children:"Basic Analysis"}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"RMS (Root Mean Square)"}),": Indicates the amplitude of the audio signal"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Energy"}),": Represents the overall energy of the audio"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Amplitude Range"}),": Min and max amplitude values"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Zero-crossing Rate (ZCR)"}),": Rate at which the signal changes sign"]}),"\n"]}),"\n",(0,r.jsx)(i.h3,{id:"spectral-features",children:"Spectral Features"}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Spectral Centroid"}),": Center of mass of the spectrum, indicating brightness of sound"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Spectral Flatness"}),": Measure of how noise-like the signal is"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Spectral Rolloff"}),": Frequency below which a specified percentage of energy lies"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Spectral Bandwidth"}),": Width of the spectrum, indicating frequency range"]}),"\n"]}),"\n",(0,r.jsx)(i.h3,{id:"advanced-analysis",children:"Advanced Analysis"}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"MFCC (Mel-frequency cepstral coefficients)"}),": Describes the short-term power spectrum"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Chromagram"}),": Represents the 12 different pitch classes"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Mel Spectrogram"}),": Mel-scaled spectrogram representation"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Harmonics-to-noise Ratio (HNR)"}),": Proportion of harmonics to noise"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Tempo"}),": Estimated beats per minute (BPM)"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Pitch"}),": Estimated fundamental frequency"]}),"\n"]}),"\n",(0,r.jsx)(i.h2,{id:"configuring-feature-extraction",children:"Configuring Feature Extraction"}),"\n",(0,r.jsxs)(i.p,{children:["You can selectively enable the features you need using the ",(0,r.jsx)(i.code,{children:"features"})," option:"]}),"\n",(0,r.jsx)(i.pre,{children:(0,r.jsx)(i.code,{className:"language-typescript",children:"const analysisProps = {\n  fileUri: 'path/to/audio/file.wav',\n  features: {\n    energy: true,\n    rms: true,\n    zcr: true,\n    mfcc: true,\n    spectralCentroid: true,\n    spectralFlatness: true,\n    spectralRolloff: true,\n    spectralBandwidth: true,\n    chromagram: true,\n    tempo: true,\n    hnr: true,\n    melSpectrogram: true,\n    pitch: true,\n  },\n};\n"})}),"\n",(0,r.jsx)(i.h2,{id:"common-use-cases",children:"Common Use Cases"}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Audio Visualization"}),": Create detailed waveform visualizations with additional metrics"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Speech Recognition"}),": Preprocess audio for speech recognition systems"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Music Analysis"}),": Analyze musical characteristics like tempo, pitch, and harmonic content"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Audio Fingerprinting"}),": Create unique fingerprints for audio identification"]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.strong,{children:"Voice Activity Detection"}),": Detect presence of speech in audio recordings"]}),"\n"]}),"\n",(0,r.jsx)(i.h2,{id:"performance-considerations",children:"Performance Considerations"}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Enable only the features you need to improve performance"}),"\n",(0,r.jsx)(i.li,{children:"For real-time analysis, consider using a lower sample rate"}),"\n",(0,r.jsx)(i.li,{children:"Processing large audio files may be resource-intensive; consider processing in chunks"}),"\n"]}),"\n",(0,r.jsxs)(i.p,{children:["For more detailed information about specific audio features and extraction methods, see the ",(0,r.jsx)(i.a,{href:"./audio-analysis",children:"Audio Features"})," and ",(0,r.jsx)(i.a,{href:"./extract-audio-analysis",children:"extractAudioAnalysis"})," documentation."]})]})}function u(e={}){const{wrapper:i}={...(0,a.R)(),...e.components};return i?(0,r.jsx)(i,{...e,children:(0,r.jsx)(d,{...e})}):d(e)}},8453:(e,i,n)=>{n.d(i,{R:()=>t,x:()=>o});var s=n(6540);const r={},a=s.createContext(r);function t(e){const i=s.useContext(a);return s.useMemo((function(){return"function"==typeof e?e(i):{...i,...e}}),[i,e])}function o(e){let i;return i=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:t(e.components),s.createElement(a.Provider,{value:i},e.children)}}}]);