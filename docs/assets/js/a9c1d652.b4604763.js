"use strict";(self.webpackChunkdocumentation_site=self.webpackChunkdocumentation_site||[]).push([[442],{7878:(e,n,a)=>{a.r(n),a.d(n,{assets:()=>d,contentTitle:()=>r,default:()=>l,frontMatter:()=>s,metadata:()=>o,toc:()=>u});var i=a(4848),t=a(8453);const s={id:"audio-analysis",title:"Audio Features",sidebar_label:"Audio Features"},r="Audio Analysis and Features",o={id:"api-reference/audio-features/audio-analysis",title:"Audio Features",description:"This section describes the various audio features that can be extracted from an audio recording, including the AudioFeatures interface, AudioAnalysis, and the extractAudioAnalysis function.",source:"@site/docs/api-reference/audio-features/audio-analysis.md",sourceDirName:"api-reference/audio-features",slug:"/api-reference/audio-features/audio-analysis",permalink:"/expo-audio-stream/docs/api-reference/audio-features/audio-analysis",draft:!1,unlisted:!1,tags:[],version:"current",frontMatter:{id:"audio-analysis",title:"Audio Features",sidebar_label:"Audio Features"},sidebar:"tutorialSidebar",previous:{title:"AudioDataEvent",permalink:"/expo-audio-stream/docs/api-reference/audio-data-event"},next:{title:"extractAudioAnalysis",permalink:"/expo-audio-stream/docs/api-reference/audio-features/extract-audio-analysis"}},d={},u=[{value:"AudioAnalysis",id:"audioanalysis",level:2},{value:"Interface",id:"interface",level:3},{value:"AudioFeatures",id:"audiofeatures",level:2},{value:"Interface",id:"interface-1",level:3},{value:"DataPoint",id:"datapoint",level:2},{value:"Interface",id:"interface-2",level:3}];function c(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",p:"p",pre:"pre",...(0,t.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.h1,{id:"audio-analysis-and-features",children:"Audio Analysis and Features"}),"\n",(0,i.jsxs)(n.p,{children:["This section describes the various audio features that can be extracted from an audio recording, including the ",(0,i.jsx)(n.code,{children:"AudioFeatures"})," interface, ",(0,i.jsx)(n.code,{children:"AudioAnalysis"}),", and the ",(0,i.jsx)(n.code,{children:"extractAudioAnalysis"})," function."]}),"\n",(0,i.jsx)(n.h2,{id:"audioanalysis",children:"AudioAnalysis"}),"\n",(0,i.jsxs)(n.p,{children:["The ",(0,i.jsx)(n.code,{children:"AudioAnalysis"})," interface represents the detailed analysis of an audio signal, including the extracted audio features."]}),"\n",(0,i.jsx)(n.h3,{id:"interface",children:"Interface"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-ts",children:"\n/**\n * Represents the complete data from the audio analysis.\n */\nexport interface AudioAnalysis {\n    pointsPerSecond: number // How many consolidated value per second\n    durationMs: number // Duration of the audio in milliseconds\n    bitDepth: number // Bit depth of the audio\n    samples: number // Size of the audio in bytes\n    numberOfChannels: number // Number of audio channels\n    sampleRate: number // Sample rate of the audio\n    dataPoints: DataPoint[] // Array of data points from the analysis.\n    amplitudeRange: {\n        min: number\n        max: number\n    }\n    // TODO: speaker detection\n    speakerChanges?: {\n        timestamp: number // Timestamp of the speaker change in milliseconds.\n        speaker: number // Speaker identifier.\n    }[]\n}\n"})}),"\n",(0,i.jsx)(n.h2,{id:"audiofeatures",children:"AudioFeatures"}),"\n",(0,i.jsxs)(n.p,{children:["The ",(0,i.jsx)(n.code,{children:"AudioFeatures"})," interface represents various audio features that can be extracted from an audio signal."]}),"\n",(0,i.jsx)(n.h3,{id:"interface-1",children:"Interface"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-ts",children:"export interface AudioFeatures {\n    energy: number // The infinite integral of the squared signal, representing the overall energy of the audio.\n    mfcc: number[] // Mel-frequency cepstral coefficients, describing the short-term power spectrum of a sound.\n    rms: number // Root mean square value, indicating the amplitude of the audio signal.\n    minAmplitude: number // Minimum amplitude value in the audio signal.\n    maxAmplitude: number // Maximum amplitude value in the audio signal.\n    zcr: number // Zero-crossing rate, indicating the rate at which the signal changes sign.\n    spectralCentroid: number // The center of mass of the spectrum, indicating the brightness of the sound.\n    spectralFlatness: number // Measure of the flatness of the spectrum, indicating how noise-like the signal is.\n    spectralRolloff: number // The frequency below which a specified percentage (usually 85%) of the total spectral energy lies.\n    spectralBandwidth: number // The width of the spectrum, indicating the range of frequencies present.\n    chromagram: number[] // Chromagram, representing the 12 different pitch classes of the audio.\n    tempo: number // Estimated tempo of the audio signal, measured in beats per minute (BPM).\n    hnr: number // Harmonics-to-noise ratio, indicating the proportion of harmonics to noise in the audio signal.\n}\n"})}),"\n",(0,i.jsx)(n.h2,{id:"datapoint",children:"DataPoint"}),"\n",(0,i.jsxs)(n.p,{children:["The ",(0,i.jsx)(n.code,{children:"DataPoint"})," interface represents individual data points extracted from an audio signal during analysis."]}),"\n",(0,i.jsx)(n.h3,{id:"interface-2",children:"Interface"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-ts",children:"/**\n * Represents a single data point in the audio analysis.\n */\nexport interface DataPoint {\n    id: number\n    amplitude: number\n    activeSpeech?: boolean\n    dB?: number\n    silent?: boolean\n    features?: AudioFeatures\n    startTime?: number\n    endTime?: number\n    // start / end position in bytes\n    startPosition?: number\n    endPosition?: number\n    // number of audio samples for this point (samples size depends on bit depth)\n    samples?: number\n    // TODO: speaker detection\n    speaker?: number\n}\n"})})]})}function l(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(c,{...e})}):c(e)}},8453:(e,n,a)=>{a.d(n,{R:()=>r,x:()=>o});var i=a(6540);const t={},s=i.createContext(t);function r(e){const n=i.useContext(s);return i.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:r(e.components),i.createElement(s.Provider,{value:n},e.children)}}}]);