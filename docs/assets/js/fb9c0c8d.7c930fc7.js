"use strict";(self.webpackChunkdocumentation_site=self.webpackChunkdocumentation_site||[]).push([[4252],{2378:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>c,contentTitle:()=>t,default:()=>h,frontMatter:()=>d,metadata:()=>r,toc:()=>l});const r=JSON.parse('{"id":"hooks/use-audio-recorder","title":"useAudioRecorder","description":"The useAudioRecorder hook provides methods and state for managing audio recording. It handles starting, stopping, pausing, and resuming recordings, and it provides analysis data for the recorded audio.","source":"@site/docs/hooks/use-audio-recorder.md","sourceDirName":"hooks","slug":"/hooks/use-audio-recorder","permalink":"/expo-audio-stream/docs/hooks/use-audio-recorder","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{"id":"use-audio-recorder","title":"useAudioRecorder","sidebar_label":"useAudioRecorder"},"sidebar":"tutorialSidebar","previous":{"title":"Shared Recording","permalink":"/expo-audio-stream/docs/usage/shared-recording"},"next":{"title":"API Intro","permalink":"/expo-audio-stream/docs/api-reference/api-intro"}}');var s=i(4848),o=i(8453);const d={id:"use-audio-recorder",title:"useAudioRecorder",sidebar_label:"useAudioRecorder"},t="useAudioRecorder",c={},l=[{value:"Parameters",id:"parameters",level:2},{value:"<code>logger</code> (optional)",id:"logger-optional",level:3},{value:"Usage",id:"usage",level:2},{value:"UseAudioRecorderState",id:"useaudiorecorderstate",level:2},{value:"RecordingConfig Options",id:"recordingconfig-options",level:2},{value:"Phone Call Handling",id:"phone-call-handling",level:3}];function a(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,o.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"useaudiorecorder",children:"useAudioRecorder"})}),"\n",(0,s.jsxs)(n.p,{children:["The ",(0,s.jsx)(n.code,{children:"useAudioRecorder"})," hook provides methods and state for managing audio recording. It handles starting, stopping, pausing, and resuming recordings, and it provides analysis data for the recorded audio."]}),"\n",(0,s.jsx)(n.h2,{id:"parameters",children:"Parameters"}),"\n",(0,s.jsxs)(n.h3,{id:"logger-optional",children:[(0,s.jsx)(n.code,{children:"logger"})," (optional)"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Type"}),": ",(0,s.jsx)(n.code,{children:"ConsoleLike"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Description"}),": A console-like object for logging debug information. Must implement ",(0,s.jsx)(n.code,{children:"log"}),", ",(0,s.jsx)(n.code,{children:"debug"}),", ",(0,s.jsx)(n.code,{children:"warn"}),", and ",(0,s.jsx)(n.code,{children:"error"})," methods."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Default"}),": ",(0,s.jsx)(n.code,{children:"undefined"})]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"usage",children:"Usage"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-tsx",children:"import { useAudioRecorder, RecordingConfig } from '@siteed/expo-audio-studio'\nimport { Audio } from 'expo-av'\nimport { Button, Text, View } from 'react-native'\n\nexport default function App() {\n    const {\n        startRecording,\n        stopRecording,\n        pauseRecording,\n        resumeRecording,\n        isRecording,\n        isPaused,\n        durationMs,\n        size,\n        analysisData,\n        compression,\n    } = useAudioRecorder({\n        logger: console,\n    })\n\n    const handleStart = async () => {\n        const { granted } = await Audio.requestPermissionsAsync()\n        if (granted) {\n            const config: RecordingConfig = {\n                interval: 500, // Emit recording data every 500ms\n                enableProcessing: true, // Enable audio analysis\n                sampleRate: 44100, // Sample rate in Hz (16000, 44100, or 48000)\n                channels: 1, // Mono recording\n                encoding: 'pcm_16bit', // PCM encoding (pcm_8bit, pcm_16bit, pcm_32bit)\n                \n                // Optional: Configure audio compression\n                compression: {\n                    enabled: false, // Set to true to enable compression\n                    format: 'aac', // 'aac' or 'opus'\n                    bitrate: 128000, // Bitrate in bits per second\n                },\n                \n                // Optional: Handle audio stream data\n                onAudioStream: async (audioData) => {\n                    console.log(`onAudioStream`, audioData)\n                },\n                \n                // Optional: Handle audio analysis data\n                onAudioAnalysis: async (analysisEvent) => {\n                    console.log(`onAudioAnalysis`, analysisEvent)\n                },\n                \n                // Optional: Handle recording interruptions\n                onRecordingInterrupted: (event) => {\n                    console.log(`Recording interrupted: ${event.reason}`)\n                },\n                \n                // Optional: Auto-resume after interruption\n                autoResumeAfterInterruption: false,\n            }\n            \n            await startRecording(config)\n        }\n    }\n\n    const handleStop = async () => {\n        const recording = await stopRecording()\n        console.log('Recording saved:', recording.fileUri)\n    }\n\n    return (\n        <View>\n            <Button title=\"Request Permission\" onPress={() => Audio.requestPermissionsAsync()} />\n            {isRecording ? (\n                <View>\n                    <Text>Duration: {durationMs / 1000} seconds</Text>\n                    <Text>Size: {size} bytes</Text>\n                    <Button title=\"Pause Recording\" onPress={pauseRecording} />\n                    <Button title=\"Stop Recording\" onPress={handleStop} />\n                </View>\n            ) : isPaused ? (\n                <View>\n                    <Text>Duration: {durationMs / 1000} seconds (Paused)</Text>\n                    <Text>Size: {size} bytes</Text>\n                    <Button title=\"Resume Recording\" onPress={resumeRecording} />\n                    <Button title=\"Stop Recording\" onPress={handleStop} />\n                </View>\n            ) : (\n                <View>\n                    <Button title=\"Start Recording\" onPress={handleStart} />\n                </View>\n            )}\n        </View>\n    )\n}\n"})}),"\n",(0,s.jsx)(n.h2,{id:"useaudiorecorderstate",children:"UseAudioRecorderState"}),"\n",(0,s.jsxs)(n.p,{children:["The ",(0,s.jsx)(n.code,{children:"useAudioRecorder"})," hook returns an object with the following properties:"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"startRecording"}),": Function to start recording with the given configuration."]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-ts",children:"startRecording: (config: RecordingConfig) => Promise<StartRecordingResult>\n"})}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"stopRecording"}),": Function to stop recording and get the result."]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-ts",children:"stopRecording: () => Promise<AudioRecording>\n"})}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"pauseRecording"}),": Function to pause the current recording."]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-ts",children:"pauseRecording: () => Promise<void>\n"})}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"resumeRecording"}),": Function to resume a paused recording."]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-ts",children:"resumeRecording: () => Promise<void>\n"})}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"isRecording"}),": ",(0,s.jsx)(n.code,{children:"boolean"})," - Indicates if recording is in progress."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"isPaused"}),": ",(0,s.jsx)(n.code,{children:"boolean"})," - Indicates if the recording is paused."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"durationMs"}),": ",(0,s.jsx)(n.code,{children:"number"})," - Duration of the recording in milliseconds."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"size"}),": ",(0,s.jsx)(n.code,{children:"number"})," - Size of the recorded audio in bytes."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"compression"}),": ",(0,s.jsx)(n.code,{children:"CompressionInfo | undefined"})," - Information about compression if enabled."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"analysisData"}),": ",(0,s.jsx)(n.code,{children:"AudioAnalysis | undefined"})," - Analysis data for the recording. Only available if ",(0,s.jsx)(n.code,{children:"enableProcessing"})," is set to ",(0,s.jsx)(n.code,{children:"true"})," in the ",(0,s.jsx)(n.code,{children:"startRecording"})," configuration."]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"recordingconfig-options",children:"RecordingConfig Options"}),"\n",(0,s.jsxs)(n.p,{children:["The ",(0,s.jsx)(n.code,{children:"startRecording"})," function accepts a configuration object with the following properties:"]}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:"Property"}),(0,s.jsx)(n.th,{children:"Type"}),(0,s.jsx)(n.th,{children:"Description"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"interval"})}),(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"number"})}),(0,s.jsx)(n.td,{children:"Interval in milliseconds at which to emit recording data"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"intervalAnalysis"})}),(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"number"})}),(0,s.jsx)(n.td,{children:"Interval in milliseconds at which to emit analysis data"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"enableProcessing"})}),(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"boolean"})}),(0,s.jsx)(n.td,{children:"Whether to enable audio analysis"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"sampleRate"})}),(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"16000 | 44100 | 48000"})}),(0,s.jsx)(n.td,{children:"Sample rate in Hz"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"channels"})}),(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"1 | 2"})}),(0,s.jsx)(n.td,{children:"Number of audio channels (1 for mono, 2 for stereo)"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"encoding"})}),(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"'pcm_8bit' | 'pcm_16bit' | 'pcm_32bit'"})}),(0,s.jsx)(n.td,{children:"PCM encoding format"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"compression"})}),(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"{ enabled: boolean, format: 'aac' | 'opus', bitrate: number }"})}),(0,s.jsx)(n.td,{children:"Audio compression settings"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"onAudioStream"})}),(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"(audioData: AudioDataEvent) => Promise<void>"})}),(0,s.jsx)(n.td,{children:"Callback for audio stream data"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"onAudioAnalysis"})}),(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"(analysisEvent: AudioAnalysisEvent) => Promise<void>"})}),(0,s.jsx)(n.td,{children:"Callback for audio analysis data"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"onRecordingInterrupted"})}),(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"(event: RecordingInterruptionEvent) => void"})}),(0,s.jsx)(n.td,{children:"Callback for recording interruptions"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"autoResumeAfterInterruption"})}),(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"boolean"})}),(0,s.jsx)(n.td,{children:"Whether to automatically resume recording after an interruption"})]})]})]}),"\n",(0,s.jsx)(n.h3,{id:"phone-call-handling",children:"Phone Call Handling"}),"\n",(0,s.jsxs)(n.p,{children:["Phone call handling is controlled by the ",(0,s.jsx)(n.code,{children:"enablePhoneStateHandling"})," option in your app's plugin configuration. By default, it is enabled to maintain backward compatibility with previous versions:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-json",children:'{\n    "expo": {\n        "plugins": [\n            [\n                "@siteed/expo-audio-studio",\n                {\n                    "enablePhoneStateHandling": true  // Default value\n                }\n            ]\n        ]\n    }\n}\n'})}),"\n",(0,s.jsx)(n.p,{children:"When enabled (default):"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"The app will automatically pause recording during phone calls"}),"\n",(0,s.jsxs)(n.li,{children:["Recording will resume after the call ends (if ",(0,s.jsx)(n.code,{children:"autoResumeAfterInterruption"})," is true)"]}),"\n",(0,s.jsxs)(n.li,{children:["The ",(0,s.jsx)(n.code,{children:"onRecordingInterrupted"})," callback will receive ",(0,s.jsx)(n.code,{children:"phoneCall"})," and ",(0,s.jsx)(n.code,{children:"phoneCallEnded"})," events"]}),"\n",(0,s.jsx)(n.li,{children:"Maintains backward compatibility with previous versions"}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"When disabled:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Recording will continue during phone calls"}),"\n",(0,s.jsx)(n.li,{children:"No phone state permissions are requested"}),"\n",(0,s.jsx)(n.li,{children:"Can be used to improve privacy by not requesting phone state permissions"}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:["For more detailed examples, see the ",(0,s.jsx)(n.a,{href:"/expo-audio-stream/docs/usage/standalone-recording",children:"Standalone Recording"})," documentation."]})]})}function h(e={}){const{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(a,{...e})}):a(e)}},8453:(e,n,i)=>{i.d(n,{R:()=>d,x:()=>t});var r=i(6540);const s={},o=r.createContext(s);function d(e){const n=r.useContext(o);return r.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function t(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:d(e.components),r.createElement(o.Provider,{value:n},e.children)}}}]);